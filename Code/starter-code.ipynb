{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Predicting Which Subreddit A Post Comes From"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "One of the most polarizing issues that has dominated headlines over the past year or so is Robert Mueller's investigation into connections between the 2016 Trump campaign and Russia. There has been a ton of discussion on cable news networks, in newspaper articles, and online about the investigation and all of the updates going along with it. For this project, I wanted to invesigate how this discussion was playing out across the website [reddit](http://www.reddit.com). Specifically, I wanted to look at the the subreddits [r/The_Donald](http://the_donald.reddit.com) and [r/The_Mueller](http://the_mueller.reddit.com) as I assumed that these two subreddits would represent different sides of the same issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Defining the Problem\n",
    "\n",
    "The problem here is twofold:\n",
    "1. What are the most important features in predicting the subreddit that a post is from?\n",
    "2. What is the most accurate prediction model that I can build to identify which subreddit a post is from?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "## Step 2: Gathering Data\n",
    "### Scraping Thread Info from Reddit.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import praw\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both URLs for the subreddits\n",
    "URL1 = \"https://www.reddit.com/r/The_Mueller/top.json\"\n",
    "URL2 = \"https://www.reddit.com/r/The_Donald/top.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create payload with parameters and request results for both URLs\n",
    "payload = {'t': 'year'}\n",
    "res1 = requests.get(URL1, headers={\"User-agent\": \"Zeke Bot 0.1\"}, params= payload)\n",
    "res2 = requests.get(URL2, headers={\"User-agent\": \"Zeke Bot 0.1\"}, params= payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `res.json()` to convert the response into a dictionary format and set this to a variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = res1.json()\n",
    "data2 = res2.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of reddit with details for scraper script I set up in reddit\n",
    "reddit = praw.Reddit(user_agent='Comment Extraction',\n",
    "                     client_id='7WcXxxBHvnT7cA', client_secret=\"ZJOOdCaK3jG4zYvX3KcABjZ4xxk\",\n",
    "                     username= 'reddit_scraper_dsi', password = 'Scraper!')\n",
    "\n",
    "# Set reddit to read only to avoid accidentally posting\n",
    "reddit.read_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_height</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>view_count</th>\n",
       "      <th>visited</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>timmyJACK</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Traitor. Upvote this so that people see it whe...</td>\n",
       "      <td>139149</td>\n",
       "      <td>https://i.redd.it/96l7405etea11.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>house_only</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>mbp4295</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>The rest hid like cowards!</td>\n",
       "      <td>20255</td>\n",
       "      <td>https://i.redd.it/jrskryzmtvnz.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>house_only</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>npor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Let's give this American the upvotes he deserves</td>\n",
       "      <td>91308</td>\n",
       "      <td>https://i.redd.it/ufiypfh52zuz.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>house_only</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>PepeTheRacistFrog</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>This Is Not A Partisan Issue. 300,000,000 Amer...</td>\n",
       "      <td>19882</td>\n",
       "      <td>https://i.redd.it/ofa6sxay2tpz.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>house_only</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>stupidstupidreddit</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>It would be a shame if the newly obtained phot...</td>\n",
       "      <td>89392</td>\n",
       "      <td>https://i.redd.it/qkpp4jnc85e11.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>house_only</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_at_utc approved_by  archived              author  \\\n",
       "0            None        None     False           timmyJACK   \n",
       "1            None        None      True             mbp4295   \n",
       "2            None        None      True                npor   \n",
       "3            None        None      True   PepeTheRacistFrog   \n",
       "4            None        None     False  stupidstupidreddit   \n",
       "\n",
       "  author_flair_background_color author_flair_css_class author_flair_richtext  \\\n",
       "0                          None                   None                    []   \n",
       "1                          None                   None                    []   \n",
       "2                          None                   None                    []   \n",
       "3                          None                   None                    []   \n",
       "4                          None                   None                    []   \n",
       "\n",
       "  author_flair_template_id author_flair_text author_flair_text_color ...  \\\n",
       "0                     None              None                    None ...   \n",
       "1                     None              None                    None ...   \n",
       "2                     None              None                    None ...   \n",
       "3                     None              None                    None ...   \n",
       "4                     None              None                    None ...   \n",
       "\n",
       "  thumbnail_height thumbnail_width  \\\n",
       "0            140.0           140.0   \n",
       "1            131.0           140.0   \n",
       "2            140.0           140.0   \n",
       "3            140.0           140.0   \n",
       "4             93.0           140.0   \n",
       "\n",
       "                                               title     ups  \\\n",
       "0  Traitor. Upvote this so that people see it whe...  139149   \n",
       "1                         The rest hid like cowards!   20255   \n",
       "2   Let's give this American the upvotes he deserves   91308   \n",
       "3  This Is Not A Partisan Issue. 300,000,000 Amer...   19882   \n",
       "4  It would be a shame if the newly obtained phot...   89392   \n",
       "\n",
       "                                   url  user_reports view_count  visited  \\\n",
       "0  https://i.redd.it/96l7405etea11.jpg            []       None    False   \n",
       "1   https://i.redd.it/jrskryzmtvnz.jpg            []       None    False   \n",
       "2   https://i.redd.it/ufiypfh52zuz.jpg            []       None    False   \n",
       "3   https://i.redd.it/ofa6sxay2tpz.jpg            []       None    False   \n",
       "4  https://i.redd.it/qkpp4jnc85e11.jpg            []       None    False   \n",
       "\n",
       "  whitelist_status wls  \n",
       "0       house_only   1  \n",
       "1       house_only   1  \n",
       "2       house_only   1  \n",
       "3       house_only   1  \n",
       "4       house_only   1  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_list = []\n",
    "\n",
    "for i in range(25):\n",
    "    my_dict1 = data1['data']['children'][i]['data']\n",
    "    my_dict2 = data2['data']['children'][i]['data']\n",
    "        \n",
    "    # Create instance of submission\n",
    "    submission1 = reddit.submission(id = data1['data']['children'][i]['data']['id'])\n",
    "    submission2 = reddit.submission(id = data2['data']['children'][i]['data']['id'])\n",
    "\n",
    "    # Remove all MoreComments objects from the list of comments\n",
    "    submission1.comments.replace_more(limit=0)\n",
    "    submission2.comments.replace_more(limit=0)\n",
    "\n",
    "    # Create a list of all top level comments\n",
    "    comment_text1 = [top_level_comment.body for top_level_comment in submission1.comments \n",
    "                     if top_level_comment.author != 'AutoModerator']\n",
    "    comment_text2 = [top_level_comment.body for top_level_comment in submission2.comments \n",
    "                     if top_level_comment.author != 'AutoModerator']\n",
    "\n",
    "    # Add comments to dictionary\n",
    "    my_dict1['comments'] = comment_text1\n",
    "    my_dict2['comments'] = comment_text2\n",
    "\n",
    "    # Append dictionary to post_list\n",
    "    post_list.append(my_dict1)\n",
    "    post_list.append(my_dict2)\n",
    "\n",
    "df = pd.DataFrame(post_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 97 columns):\n",
      "approved_at_utc                  0 non-null object\n",
      "approved_by                      0 non-null object\n",
      "archived                         50 non-null bool\n",
      "author                           50 non-null object\n",
      "author_flair_background_color    25 non-null object\n",
      "author_flair_css_class           20 non-null object\n",
      "author_flair_richtext            46 non-null object\n",
      "author_flair_template_id         7 non-null object\n",
      "author_flair_text                21 non-null object\n",
      "author_flair_text_color          25 non-null object\n",
      "author_flair_type                46 non-null object\n",
      "author_fullname                  46 non-null object\n",
      "banned_at_utc                    0 non-null object\n",
      "banned_by                        0 non-null object\n",
      "can_gild                         50 non-null bool\n",
      "can_mod_post                     50 non-null bool\n",
      "category                         0 non-null object\n",
      "clicked                          50 non-null bool\n",
      "comments                         50 non-null object\n",
      "content_categories               0 non-null object\n",
      "contest_mode                     50 non-null bool\n",
      "created                          50 non-null float64\n",
      "created_utc                      50 non-null float64\n",
      "crosspost_parent                 1 non-null object\n",
      "crosspost_parent_list            1 non-null object\n",
      "distinguished                    0 non-null object\n",
      "domain                           50 non-null object\n",
      "downs                            50 non-null int64\n",
      "edited                           50 non-null bool\n",
      "gilded                           50 non-null int64\n",
      "hidden                           50 non-null bool\n",
      "hide_score                       50 non-null bool\n",
      "id                               50 non-null object\n",
      "is_crosspostable                 50 non-null bool\n",
      "is_meta                          50 non-null bool\n",
      "is_original_content              50 non-null bool\n",
      "is_reddit_media_domain           50 non-null bool\n",
      "is_self                          50 non-null bool\n",
      "is_video                         50 non-null bool\n",
      "likes                            0 non-null object\n",
      "link_flair_background_color      50 non-null object\n",
      "link_flair_css_class             23 non-null object\n",
      "link_flair_richtext              50 non-null object\n",
      "link_flair_template_id           11 non-null object\n",
      "link_flair_text                  23 non-null object\n",
      "link_flair_text_color            50 non-null object\n",
      "link_flair_type                  50 non-null object\n",
      "locked                           50 non-null bool\n",
      "media                            2 non-null object\n",
      "media_embed                      50 non-null object\n",
      "media_only                       50 non-null bool\n",
      "mod_note                         0 non-null object\n",
      "mod_reason_by                    0 non-null object\n",
      "mod_reason_title                 0 non-null object\n",
      "mod_reports                      50 non-null object\n",
      "name                             50 non-null object\n",
      "no_follow                        50 non-null bool\n",
      "num_comments                     50 non-null int64\n",
      "num_crossposts                   50 non-null int64\n",
      "num_reports                      0 non-null object\n",
      "over_18                          50 non-null bool\n",
      "parent_whitelist_status          50 non-null object\n",
      "permalink                        50 non-null object\n",
      "pinned                           50 non-null bool\n",
      "post_hint                        49 non-null object\n",
      "preview                          49 non-null object\n",
      "previous_visits                  1 non-null object\n",
      "pwls                             50 non-null int64\n",
      "quarantine                       50 non-null bool\n",
      "removal_reason                   0 non-null object\n",
      "report_reasons                   0 non-null object\n",
      "saved                            50 non-null bool\n",
      "score                            50 non-null int64\n",
      "secure_media                     2 non-null object\n",
      "secure_media_embed               50 non-null object\n",
      "selftext                         50 non-null object\n",
      "selftext_html                    0 non-null object\n",
      "send_replies                     50 non-null bool\n",
      "spoiler                          50 non-null bool\n",
      "stickied                         50 non-null bool\n",
      "subreddit                        50 non-null object\n",
      "subreddit_id                     50 non-null object\n",
      "subreddit_name_prefixed          50 non-null object\n",
      "subreddit_subscribers            50 non-null int64\n",
      "subreddit_type                   50 non-null object\n",
      "suggested_sort                   0 non-null object\n",
      "thumbnail                        50 non-null object\n",
      "thumbnail_height                 49 non-null float64\n",
      "thumbnail_width                  49 non-null float64\n",
      "title                            50 non-null object\n",
      "ups                              50 non-null int64\n",
      "url                              50 non-null object\n",
      "user_reports                     50 non-null object\n",
      "view_count                       0 non-null object\n",
      "visited                          50 non-null bool\n",
      "whitelist_status                 50 non-null object\n",
      "wls                              50 non-null int64\n",
      "dtypes: bool(25), float64(4), int64(9), object(59)\n",
      "memory usage: 29.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('raw_reddit_scrape.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting more results\n",
    "\n",
    "By default, Reddit will give you the top 25 posts. The cell below uses a for loop to collect as much data as possible. The subreddit [r/The_Mueller](http://the_mueller.reddit.com) had fewer than 1000 posts for me to collect, so I instead collected 975. To keep the classes balanced, I collected the same number of posts from [r/The_Donald](http://the_donald.reddit.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop Number: 1 df shape: (100, 97)\n",
      "Loop Number: 2 df shape: (150, 98)\n",
      "Loop Number: 3 df shape: (200, 98)\n",
      "Loop Number: 4 df shape: (250, 98)\n",
      "Loop Number: 5 df shape: (300, 98)\n",
      "Loop Number: 6 df shape: (350, 98)\n",
      "Loop Number: 7 df shape: (400, 98)\n",
      "Loop Number: 8 df shape: (450, 98)\n",
      "Loop Number: 9 df shape: (500, 98)\n",
      "Loop Number: 10 df shape: (550, 98)\n",
      "Loop Number: 11 df shape: (600, 98)\n",
      "Loop Number: 12 df shape: (650, 98)\n",
      "Loop Number: 13 df shape: (700, 98)\n",
      "Loop Number: 14 df shape: (750, 98)\n",
      "Loop Number: 15 df shape: (800, 98)\n",
      "Loop Number: 16 df shape: (850, 98)\n",
      "Loop Number: 17 df shape: (900, 98)\n",
      "Loop Number: 18 df shape: (950, 98)\n",
      "Loop Number: 19 df shape: (1000, 98)\n",
      "Loop Number: 20 df shape: (1050, 98)\n",
      "Loop Number: 21 df shape: (1100, 98)\n",
      "Loop Number: 22 df shape: (1150, 98)\n",
      "Loop Number: 23 df shape: (1200, 98)\n",
      "Loop Number: 24 df shape: (1250, 98)\n",
      "Loop Number: 25 df shape: (1300, 98)\n",
      "Loop Number: 26 df shape: (1350, 98)\n",
      "Loop Number: 27 df shape: (1400, 98)\n",
      "Loop Number: 28 df shape: (1450, 98)\n",
      "Loop Number: 29 df shape: (1500, 98)\n",
      "Loop Number: 30 df shape: (1550, 98)\n",
      "Loop Number: 31 df shape: (1600, 98)\n",
      "Loop Number: 32 df shape: (1650, 98)\n",
      "Loop Number: 33 df shape: (1700, 98)\n",
      "Loop Number: 34 df shape: (1750, 98)\n",
      "Loop Number: 35 df shape: (1800, 98)\n",
      "Loop Number: 36 df shape: (1850, 98)\n",
      "Loop Number: 37 df shape: (1900, 98)\n",
      "Loop Number: 38 df shape: (1950, 98)\n"
     ]
    }
   ],
   "source": [
    "for j in range(1, 39):\n",
    "    # Create empty list of dictionaries to append to dataframe\n",
    "    post_list = []\n",
    "    \n",
    "    # Find the afters for each of the urls\n",
    "    after1 = data1['data']['after']\n",
    "    after2 = data2['data']['after']\n",
    "    \n",
    "    # Create parameter dictionaries for both urls\n",
    "    payload1 = {'t': 'year', 'after': after1}\n",
    "    payload2 = {'t': 'year', 'after': after2}\n",
    "    \n",
    "    # Create both urls\n",
    "    url_temp1 = 'https://www.reddit.com/r/The_Mueller/top.json'\n",
    "    url_temp2 = 'https://www.reddit.com/r/The_Donald/top.json'\n",
    "    \n",
    "    # Get with requests from both urls\n",
    "    res1 = requests.get(url_temp1, headers={'User-agent': 'Zeke Bot 0.1'}, params = payload1)\n",
    "    res2 = requests.get(url_temp2, headers={'User-agent': 'Zeke Bot 0.1'}, params = payload2)\n",
    "    \n",
    "    # Replace values of data1 and data2\n",
    "    data1, data2 = res1.json(), res2.json()\n",
    "    \n",
    "    # Iterate through all children of first subreddit (posts)\n",
    "    for i in range(len(data1['data']['children'])):\n",
    "        \n",
    "        # Create dictionaries from json\n",
    "        my_dict1 = data1['data']['children'][i]['data']\n",
    "        \n",
    "        # Create instance of submission\n",
    "        submission1 = reddit.submission(id = data1['data']['children'][i]['data']['id'])\n",
    "        \n",
    "        # Remove all MoreComments objects from the list of comments\n",
    "        submission1.comments.replace_more(limit=0)\n",
    "        \n",
    "        # Create a list of all top level comments\n",
    "        comment_text1 = [top_level_comment.body for top_level_comment in submission1.comments \n",
    "                         if top_level_comment.author != 'AutoModerator']\n",
    "        \n",
    "        # Add comments to dictionary\n",
    "        my_dict1['comments'] = comment_text1\n",
    "        \n",
    "        # Append dictionary to post_list\n",
    "        post_list.append(my_dict1)\n",
    "\n",
    "    # Iterate through all children of second subreddit (posts)\n",
    "    for i in range(len(data2['data']['children'])):\n",
    "        \n",
    "        # Create dictionaries from json\n",
    "        my_dict2 = data2['data']['children'][i]['data']\n",
    "        \n",
    "        # Create instance of submission\n",
    "        submission2 = reddit.submission(id = data2['data']['children'][i]['data']['id'])\n",
    "        \n",
    "        # Remove all MoreComments objects from the list of comments\n",
    "        submission2.comments.replace_more(limit=0)\n",
    "        \n",
    "        # Create a list of all top level comments\n",
    "        comment_text2 = [top_level_comment.body for top_level_comment in submission2.comments \n",
    "                         if top_level_comment.author != 'AutoModerator']\n",
    "        \n",
    "        # Add comments to dictionary\n",
    "        my_dict2['comments'] = comment_text2\n",
    "        \n",
    "        # Append dictionary to post_list\n",
    "        post_list.append(my_dict2)\n",
    "\n",
    "    # Add post list to dataframe and save dataframe after each set of 25 posts has been processed\n",
    "    temp_df = pd.DataFrame(post_list)\n",
    "    df = pd.concat([df, temp_df], axis=0, ignore_index=True)\n",
    "    df.to_csv('../Data/raw_reddit_scrape.csv')\n",
    "        \n",
    "    print('Loop Number:', j, 'df shape:', df.shape)    \n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save the results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "df.to_csv('../Data/raw_reddit_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1950, 98)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: EDA and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view_count                       1950\n",
       "num_reports                      1950\n",
       "approved_by                      1950\n",
       "banned_at_utc                    1950\n",
       "banned_by                        1950\n",
       "category                         1950\n",
       "content_categories               1950\n",
       "mod_note                         1950\n",
       "mod_reason_by                    1950\n",
       "mod_reason_title                 1950\n",
       "likes                            1950\n",
       "approved_at_utc                  1950\n",
       "removal_reason                   1950\n",
       "report_reasons                   1950\n",
       "distinguished                    1944\n",
       "author_cakeday                   1936\n",
       "suggested_sort                   1933\n",
       "selftext_html                    1929\n",
       "crosspost_parent_list            1909\n",
       "crosspost_parent                 1909\n",
       "previous_visits                  1887\n",
       "secure_media                     1881\n",
       "media                            1881\n",
       "author_flair_template_id         1679\n",
       "link_flair_template_id           1461\n",
       "link_flair_css_class             1175\n",
       "link_flair_text                  1175\n",
       "author_flair_css_class           1157\n",
       "author_flair_text                1094\n",
       "author_flair_text_color          1055\n",
       "author_flair_background_color    1055\n",
       "thumbnail_width                    60\n",
       "thumbnail_height                   60\n",
       "preview                            51\n",
       "post_hint                          51\n",
       "author_fullname                    38\n",
       "author_flair_type                  38\n",
       "author_flair_richtext              38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of df to manipulate\n",
    "red_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that contain only null values\n",
    "null_cols = red_df.isnull().sum()[red_df.isnull().sum() == 1950].keys().tolist()\n",
    "red_df.drop(labels = null_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all unwanted columns\n",
    "unwanted_cols = ['preview', 'thumbnail_width', 'thumbnail_height', 'link_flair_template_id','author_cakeday',\n",
    "                 'suggested_sort', 'media', 'secure_media', 'crosspost_parent_list', 'author_flair_template_id',\n",
    "                 'author_flair_css_class', 'link_flair_css_class', 'author_flair_background_color',\n",
    "                 'author_flair_type', 'author_flair_richtext', 'whitelist_status', 'wls',\n",
    "                 'visited', 'subreddit_id', 'subreddit_subscribers', 'subreddit_name_prefixed', 'can_gild',\n",
    "                 'author_fullname', 'author_flair_text_color', 'can_mod_post', 'clicked', 'contest_mode',\n",
    "                 'created', 'created_utc', 'crosspost_parent', 'distinguished', 'hidden', 'edited',\n",
    "                 'hide_score', 'is_crosspostable', 'is_meta', 'is_original_content', 'link_flair_background_color',\n",
    "                 'link_flair_text_color', 'link_flair_type', 'link_flair_richtext', 'locked', 'media_only',\n",
    "                 'no_follow', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'pwls',\n",
    "                 'quarantine', 'saved', 'secure_media_embed', 'spoiler', 'stickied', 'subreddit_type', \n",
    "                 'user_reports', 'mod_reports', 'previous_visits', 'selftext_html', 'media_embed', 'thumbnail']\n",
    "red_df.drop(labels=unwanted_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['archived', 'author', 'author_flair_text', 'comments', 'domain',\n",
       "       'downs', 'gilded', 'id', 'is_reddit_media_domain', 'is_self',\n",
       "       'is_video', 'link_flair_text', 'name', 'num_comments', 'num_crossposts',\n",
       "       'post_hint', 'score', 'selftext', 'send_replies', 'subreddit', 'title',\n",
       "       'ups', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure correct columns remain\n",
    "red_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1950, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "archived                    bool\n",
       "author                    object\n",
       "author_flair_text         object\n",
       "comments                  object\n",
       "domain                    object\n",
       "downs                      int64\n",
       "gilded                     int64\n",
       "id                        object\n",
       "is_reddit_media_domain      bool\n",
       "is_self                     bool\n",
       "is_video                    bool\n",
       "link_flair_text           object\n",
       "name                      object\n",
       "num_comments               int64\n",
       "num_crossposts             int64\n",
       "post_hint                 object\n",
       "score                      int64\n",
       "selftext                  object\n",
       "send_replies                bool\n",
       "subreddit                 object\n",
       "title                     object\n",
       "ups                        int64\n",
       "url                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap True/False to 1/0 for boolean columns\n",
    "bool_dict = {True: 1, False: 0}\n",
    "\n",
    "bool_cols = ['archived', 'is_reddit_media_domain', 'is_self', 'is_video', 'send_replies']\n",
    "for col in bool_cols:\n",
    "    red_df[col] = red_df[col].map(bool_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The_Mueller    975\n",
       "The_Donald     975\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to make sure classes are balanced\n",
    "red_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    975\n",
       "0    975\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remap subreddits to 1 and 0, distinction between positive and negative class is arbitrary\n",
    "red_df['subreddit'] = red_df['subreddit'].map(lambda cell: 1 if cell == 'The_Mueller' else 0)\n",
    "\n",
    "red_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values in both flair text caterogies with empty strings\n",
    "red_df['author_flair_text'].fillna('', inplace=True)\n",
    "\n",
    "red_df['link_flair_text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two flair text features into one and then drop original features\n",
    "red_df['flair_text'] = red_df['author_flair_text'] + red_df['link_flair_text']\n",
    "red_df.drop(['author_flair_text', 'link_flair_text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(red_df['author'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several features are no longer helpful:\n",
    "- There are over 1000 unique authors in a dataset comprised of fewer than 2000 posts, so I will not use this feature. \n",
    "- The id and name features are also unhelfpul as they are just unique identifiers for each post. \n",
    "- The information I'm most interested in from the url feature is captured in the domain feature.\n",
    "\n",
    "All three features are dropped in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df.drop(['author', 'id', 'url', 'name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "archived                   int64\n",
       "comments                  object\n",
       "domain                    object\n",
       "downs                      int64\n",
       "gilded                     int64\n",
       "is_reddit_media_domain     int64\n",
       "is_self                    int64\n",
       "is_video                   int64\n",
       "num_comments               int64\n",
       "num_crossposts             int64\n",
       "post_hint                 object\n",
       "score                      int64\n",
       "selftext                  object\n",
       "send_replies               int64\n",
       "subreddit                  int64\n",
       "title                     object\n",
       "ups                        int64\n",
       "flair_text                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last bit of data cleaning to do before moving into NLP is to dummy the post_hint variable. This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df = pd.get_dummies(red_df, columns=['post_hint'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is ready to be processed using NLP methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df.to_csv('../Data/reddit_scrape_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "## Step 4: Modeling\n",
    "\n",
    "#### Import necessary modeling and NLP packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier  \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model: title + selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y and then train/test split\n",
    "X1 = red_df['title'] + red_df['selftext']\n",
    "y1 = red_df['subreddit']\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instanstiate count vectorizer object and transform X data\n",
    "cvect = CountVectorizer(stop_words='english')\n",
    "\n",
    "X1_train_cvect = cvect.fit_transform(X1_train)\n",
    "X1_test_cvect = cvect.transform(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate 2 different classifier models\n",
    "logreg = LogisticRegression()\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70491803 0.73921971 0.74332649]\n",
      "0.7291547446729728\n"
     ]
    }
   ],
   "source": [
    "nb_score = cross_val_score(nb, X1_train_cvect, y1_train)\n",
    "print(nb_score)\n",
    "print(nb_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Scale data before using logistic regression\n",
    "ss = StandardScaler()\n",
    "X1_train_scaled = ss.fit_transform(X1_train_cvect.todense())\n",
    "X1_test_scaled = ss.transform(X1_test_cvect.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68442623 0.69609856 0.65297741]\n",
      "0.6778340682891799\n"
     ]
    }
   ],
   "source": [
    "logreg_score = cross_val_score(logreg, X1_train_scaled, y1_train)\n",
    "print(logreg_score)\n",
    "print(logreg_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating 2 simple models, a logistic regression and a multinomial naive bayes, it seems the naive bayes had a slightly better fit. Both models still have a lot of room for improvement. Below I will check for overfit on each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.981532147742818\n",
      "Test Score: 0.7028688524590164\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X1_train_cvect, y1_train)\n",
    "m1_log_score = logreg.score(X1_test_scaled, y1_test)\n",
    "log_scores = [m1_log_score]\n",
    "print('Train Score:', logreg.score(X1_train_scaled, y1_train))\n",
    "print('Test Score:', logreg.score(X1_test_scaled, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9411764705882353\n",
      "Test Score: 0.7438524590163934\n"
     ]
    }
   ],
   "source": [
    "nb.fit(X1_train_cvect, y1_train)\n",
    "m1_nb_score = nb.score(X1_test_cvect, y1_test)\n",
    "nb_scores = [m1_nb_score]\n",
    "print('Train Score:', nb.score(X1_train_cvect, y1_train))\n",
    "print('Test Score:', nb.score(X1_test_cvect, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5688"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.466153846153848\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "for i in X1.index:\n",
    "    word_count += len(X1[i].split())\n",
    "print(word_count/1950)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will attempt this again with a TfidfVectorizer instead of a count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvect = TfidfVectorizer()\n",
    "tvect.fit(X1_train)\n",
    "\n",
    "X1_train_tvect = tvect.transform(X1_train)\n",
    "X1_test_tvect = tvect.transform(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_t = LogisticRegression()\n",
    "nb_t = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7418032786885246\n"
     ]
    }
   ],
   "source": [
    "nb_t.fit(X1_train_tvect, y1_train)\n",
    "m1_nbt_score = nb_t.score(X1_test_tvect, y1_test)\n",
    "print(m1_nbt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_t = StandardScaler()\n",
    "X1_train_t_scaled = ss_t.fit_transform(X1_train_tvect.todense())\n",
    "X1_test_t_scaled = ss_t.transform(X1_test_tvect.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885245901639344\n"
     ]
    }
   ],
   "source": [
    "logreg_t.fit(X1_train_t_scaled, y1_train)\n",
    "m1_logt_score = logreg_t.score(X1_test_t_scaled, y1_test)\n",
    "print(m1_logt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "      <th>vectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.702869</td>\n",
       "      <td>CountVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.743852</td>\n",
       "      <td>CountVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.741803</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           classifier     score       vectorizer\n",
       "0  LogisticRegression  0.702869  CountVectorizer\n",
       "1       MultinomialNB  0.743852  CountVectorizer\n",
       "2  LogisticRegression  0.688525  TfidfVectorizer\n",
       "3       MultinomialNB  0.741803  TfidfVectorizer"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_scores = [\n",
    "    {'score':m1_log_score, \n",
    "     'vectorizer': 'CountVectorizer',\n",
    "     'classifier': 'LogisticRegression'\n",
    "    },\n",
    "    {'score':m1_nb_score, \n",
    "     'vectorizer': 'CountVectorizer',\n",
    "     'classifier': 'MultinomialNB'\n",
    "    },\n",
    "    {'score':m1_logt_score, \n",
    "     'vectorizer': 'TfidfVectorizer',\n",
    "     'classifier': 'LogisticRegression'\n",
    "    },\n",
    "    {'score':m1_nbt_score, \n",
    "     'vectorizer': 'TfidfVectorizer',\n",
    "     'classifier': 'MultinomialNB'\n",
    "    }]\n",
    "m1_scores=pd.DataFrame(m1_scores)\n",
    "m1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.barh([0, .8, 2.0, 2.8],\n",
    "         m1_scores['score'],\n",
    "         color = ['b', 'g', 'b', 'g'],\n",
    "         alpha = 0.8,\n",
    "         label=m1_scores['classifier'])\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.title(\"Models Based on Title and Self Text Were Weak Learners\", size=20, ha='left', position=(0,1))\n",
    "ax = plt.gca()\n",
    "sides = ['left', 'right', 'top', 'bottom']\n",
    "for side in sides:\n",
    "    ax.spines[side].set_visible(False)\n",
    "plt.yticks([0.4, 2.4], ['Count Vectorizer', 'Tf-IDF Vectorizer'], size=18, alpha=0.7)\n",
    "blue_patch = mpatches.Patch(color='b', label='Logistic Regression')\n",
    "green_patch = mpatches.Patch(color='g', label='Multinomial Naive Bayes')\n",
    "plt.legend(handles=[blue_patch, green_patch], bbox_to_anchor=(1,0.95), prop={'size': 14})\n",
    "barh_y_vals = [0, .8, 2.0, 2.8]\n",
    "for i in range(4):\n",
    "    plt.text(m1_scores.loc[i,'score']-.05,\n",
    "             barh_y_vals[i],\n",
    "             str(round(m1_scores.loc[i,'score'],3)),\n",
    "             color='w',\n",
    "             size=18,\n",
    "             ha='right')\n",
    "plt.savefig('./Assets/model_1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models were severely overfit, performing significantly better on training data than on testing data. This may be because of the small amount of information being used for each prediction relative to the number of features. There are over 5500 features in the prediction matrix, while the average number of words being evaluated for each post is only about 20. In order to make this model more accurate, I will try introducing more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Add all numeric metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.concat([red_df.select_dtypes('int64'), red_df['title'] + red_df['selftext']], axis=1).drop('subreddit', axis=1)\n",
    "y2 = red_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect2 = CountVectorizer(stop_words='english')\n",
    "\n",
    "cvect2.fit(X2_train[0])\n",
    "X2_train_cv = pd.DataFrame(cvect2.transform(X2_train[0]).todense(), columns=cvect2.get_feature_names(), index=X2_train.index)\n",
    "X2_test_cv =  pd.DataFrame(cvect2.transform(X2_test[0]).todense(), columns=cvect2.get_feature_names(), index=X2_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = pd.concat([X2_train.drop(0, axis=1), X2_train_cv], axis=1)\n",
    "X2_test = pd.concat([X2_test.drop(0, axis=1), X2_test_cv], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression()\n",
    "nb2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79918033 0.79098361 0.73045267]\n",
      "0.7735388697744496\n"
     ]
    }
   ],
   "source": [
    "nb2_score = cross_val_score(nb2, X2_train, y2_train)\n",
    "print(nb2_score)\n",
    "print(nb2_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss2 = StandardScaler()\n",
    "\n",
    "X2_train_scaled = ss2.fit_transform(X2_train)\n",
    "X2_test_scaled = ss2.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78483607 0.71516393 0.76337449]\n",
      "0.7544581618655694\n"
     ]
    }
   ],
   "source": [
    "logreg2_score = cross_val_score(logreg2, X2_train_scaled, y2_train)\n",
    "print(logreg2_score)\n",
    "print(logreg2_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including this information made both models stronger. I will check both models on the testing data below to see how they perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9986320109439124\n",
      "Test score: 0.7745901639344263\n"
     ]
    }
   ],
   "source": [
    "logreg2.fit(X2_train_scaled, y2_train)\n",
    "log_scores.append(logreg2.score(X2_test_scaled, y2_test))\n",
    "print('Train score:', logreg2.score(X2_train_scaled, y2_train))\n",
    "print('Test score:', logreg2.score(X2_test_scaled, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8242134062927496\n",
      "Test score: 0.7479508196721312\n"
     ]
    }
   ],
   "source": [
    "nb2.fit(X2_train, y2_train)\n",
    "nb_scores.append(nb2.score(X2_test, y2_test))\n",
    "print('Train score:', nb2.score(X2_train, y2_train))\n",
    "print('Test score:', nb2.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Add Flair Text and Domain dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([              'archived',                  'downs',\n",
       "                       'gilded', 'is_reddit_media_domain',\n",
       "                      'is_self',               'is_video',\n",
       "                 'num_comments',         'num_crossposts',\n",
       "                        'score',           'send_replies',\n",
       "                          'ups',                        0],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'(\\w+)\\.\\w{2}\\.\\w{2}|\\w+\\.(\\w+)\\.\\S*|(\\w+)\\.\\S*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x)\n",
    "    token = [a for a in tokens[0] if a != '']\n",
    "    return token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 redd\n",
       "1                 redd\n",
       "2                 redd\n",
       "3                 redd\n",
       "4                 redd\n",
       "5              foxnews\n",
       "6                 redd\n",
       "7              magaimg\n",
       "8                imgur\n",
       "9              twitter\n",
       "10            newsweek\n",
       "11             twitter\n",
       "12                redd\n",
       "13                redd\n",
       "14                redd\n",
       "15               imgur\n",
       "16               imgur\n",
       "17                redd\n",
       "18               imgur\n",
       "19              nypost\n",
       "20                redd\n",
       "21                redd\n",
       "22                redd\n",
       "23                redd\n",
       "24         motherjones\n",
       "25             archive\n",
       "26                redd\n",
       "27              nypost\n",
       "28                redd\n",
       "29                redd\n",
       "             ...      \n",
       "1920          theonion\n",
       "1921           twitter\n",
       "1922          chicago2\n",
       "1923             imgur\n",
       "1924    chicagotribune\n",
       "1925           thehill\n",
       "1926              self\n",
       "1927             imgur\n",
       "1928              redd\n",
       "1929              redd\n",
       "1930              redd\n",
       "1931           archive\n",
       "1932             imgur\n",
       "1933              redd\n",
       "1934              redd\n",
       "1935           magaimg\n",
       "1936              redd\n",
       "1937           twitter\n",
       "1938              redd\n",
       "1939              redd\n",
       "1940             imgur\n",
       "1941             imgur\n",
       "1942           nytimes\n",
       "1943              redd\n",
       "1944           reuters\n",
       "1945             imgur\n",
       "1946           twitter\n",
       "1947           magaimg\n",
       "1948              redd\n",
       "1949              redd\n",
       "Name: domain, Length: 1950, dtype: object"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df['domain'] = red_df['domain'].map(domain_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.concat([X2, red_df['flair_text'], pd.get_dummies(red_df['domain'], prefix='domain', drop_first=True)], axis=1)\n",
    "y3 = red_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 179)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create custom stop words from nltk and sklearn stop words together\n",
    "s1 = set(ENGLISH_STOP_WORDS)\n",
    "s2 = set(stopwords.words('english'))\n",
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine both sets of stopwords into a set\n",
    "stops = s1.union(s2)\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create count vectorizers for each text feature\n",
    "cv3_title = CountVectorizer(stop_words=stops)\n",
    "cv3_flair = CountVectorizer(stop_words=stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split data\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the train and test data from the title column (labeled 0)\n",
    "# Make the transformed sparse matrix into a dataframe with appropriate feature names\n",
    "cv3_title.fit(X3_train[0])\n",
    "X3_train_title_vect = pd.DataFrame(cv3_title.transform(X3_train[0]).todense(),\n",
    "                                   columns = cv3_title.get_feature_names(),\n",
    "                                   index = X3_train.index)\n",
    "X3_test_title_vect = pd.DataFrame(cv3_title.transform(X3_test[0]).todense(),\n",
    "                                  columns = cv3_title.get_feature_names(),\n",
    "                                  index = X3_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the train and test data from the flair_text column \n",
    "# Make the transformed sparse matrix into a dataframe with appropriate feature names\n",
    "cv3_flair.fit(X3_train['flair_text'])\n",
    "X3_train_flair_vect = pd.DataFrame(cv3_flair.transform(X3_train['flair_text']).todense(),\n",
    "                                   columns = cv3_flair.get_feature_names(),\n",
    "                                   index = X3_train.index)\n",
    "X3_test_flair_vect = pd.DataFrame(cv3_flair.transform(X3_test['flair_text']).todense(),\n",
    "                                  columns = cv3_flair.get_feature_names(),\n",
    "                                  index = X3_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1462, 5351), (1462, 498))"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train_title_vect.shape, X3_train_flair_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_title_sets = [X3_train_title_vect, X3_test_title_vect]\n",
    "X3_flair_sets = [X3_train_flair_vect, X3_test_flair_vect]\n",
    "\n",
    "# Append newly created dataframes from vectorized columns back to original dataframes\n",
    "# Also drop original columns that have been vectorized\n",
    "for s in X3_title_sets:\n",
    "    \n",
    "    # Discard all vectorized features that were purely numeric\n",
    "    cols = [col for col in cv3_title.get_feature_names() if not col.isnumeric()]\n",
    "    \n",
    "    # Prepend 'title_self__' to columns from vectorized title and selftext\n",
    "    col_names = ['title+self__' + col for col in cols]\n",
    "    s = s[cols]\n",
    "    s.columns = col_names\n",
    "    if s.shape[0] ==1462:\n",
    "        X3_train = pd.concat([X3_train.drop(0, axis=1), s], axis=1)\n",
    "    else:\n",
    "        X3_test = pd.concat([X3_test.drop(0, axis=1), s], axis=1)\n",
    "\n",
    "for f in X3_flair_sets:\n",
    "    \n",
    "    # Discard all vectorized features that were purely numeric\n",
    "    flair_cols = [col for col in cv3_flair.get_feature_names() if not col.isnumeric()]\n",
    "    \n",
    "    # Prepend 'flair__' to columns from vectorized flair text\n",
    "    flair_col_names = ['flair__' + col for col in flair_cols]\n",
    "    f = f[flair_cols]\n",
    "    f.columns = flair_col_names\n",
    "    if f.shape[0] ==1462:\n",
    "        X3_train = pd.concat([X3_train.drop('flair_text', axis=1), f], axis=1)\n",
    "    else:\n",
    "        X3_test = pd.concat([X3_test.drop('flair_text', axis=1), f], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1462, 6038), (488, 6038))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train.shape, X3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   29.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('ss', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logreg__penalty': ('l1', 'l2'), 'logreg__C': (0.15, 0.2, 0.25, 0.3, 0.35)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use gridsearchCV to find best parameters for the logistic regression\n",
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "grid_params3 = {\n",
    "    'logreg__penalty': ('l1', 'l2'), \n",
    "    'logreg__C': (0.15, 0.20, 0.25, 0.30, 0.35)\n",
    "}\n",
    "gs3 = GridSearchCV(pipe3, grid_params3, verbose=1)\n",
    "\n",
    "gs3.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below represent the best scores with stop_words = union of nltk and sklearn stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896032831737346"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 0.25, 'logreg__penalty': 'l1'}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057377049180327"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.score(X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores.append(gs3.score(X3_test, y3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to try the logistic regression with only scaling the originially numeric features and not any of the one-hot-encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols3 = X3_train.select_dtypes('uint8').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale all features that are not dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1462 entries, 1863 to 1126\n",
      "Columns: 6038 entries, archived to flair__Ñ€Ð¾ÑÑÐ¸Ñ\n",
      "dtypes: int64(5860), uint8(178)\n",
      "memory usage: 65.6 MB\n"
     ]
    }
   ],
   "source": [
    "X3_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_cols3 = [col for col in X3_train.columns if col not in dummy_cols3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train_scale_all = X3_train[scaling_cols3].copy()\n",
    "X3_test_scale_all = X3_test[scaling_cols3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss3_all = StandardScaler()\n",
    "ss3_all.fit(X3_train_scale_all)\n",
    "X3_train_scale_all_t = pd.DataFrame(ss3_all.transform(X3_train_scale_all),\n",
    "                                    columns=X3_train_scale_all.columns,\n",
    "                                    index=X3_train.index)\n",
    "X3_test_scale_all_t = pd.DataFrame(ss3_all.transform(X3_test_scale_all),\n",
    "                                   columns=X3_test_scale_all.columns,\n",
    "                                   index=X3_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X3_train_scaled_all = pd.concat([X3_train.drop(scaling_cols3, axis=1), X3_train_scale_all_t], axis=1)\n",
    "X3_test_scaled_all = pd.concat([X3_test.drop(scaling_cols3, axis=1), X3_test_scale_all_t], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   33.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ('l1', 'l2'), 'C': (0.01, 0.05, 0.1, 0.25, 0.5, 1)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3_a = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    {\n",
    "        'penalty': ('l1', 'l2'),\n",
    "        'C': (0.01, 0.05, 0.1, 0.25, 0.5, 1)\n",
    "    },\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gs3_a.fit(X3_train_scaled_all, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8830369357045144"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3_a.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3_a.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9016393442622951"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3_a.score(X3_test_scaled_all, y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_feat_cols = [col for col in X3_train.columns if \"__\" in col]\n",
    "scaling_cols3_b = [col for col in X3_train.columns if col not in text_feat_cols and col not in dummy_cols3]\n",
    "len(scaling_cols3_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train_scale_some = X3_train[scaling_cols3_b].copy()\n",
    "X3_test_scale_some = X3_test[scaling_cols3_b].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss3_some = StandardScaler()\n",
    "ss3_some.fit(X3_train_scale_some)\n",
    "X3_train_scale_some_t = pd.DataFrame(ss3_some.transform(X3_train_scale_some),\n",
    "                                    columns=X3_train_scale_some.columns,\n",
    "                                    index=X3_train.index)\n",
    "X3_test_scale_some_t = pd.DataFrame(ss3_some.transform(X3_test_scale_some),\n",
    "                                   columns=X3_test_scale_some.columns,\n",
    "                                   index=X3_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train_scaled_some = pd.concat([X3_train.drop(scaling_cols3_b, axis=1), X3_train_scale_some_t], axis=1)\n",
    "X3_test_scaled_some = pd.concat([X3_test.drop(scaling_cols3_b, axis=1), X3_test_scale_some_t], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ('l1', 'l2'), 'C': (0.01, 0.05, 0.1, 0.25, 0.5, 1)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3_b = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    {\n",
    "        'penalty': ('l1', 'l2'),\n",
    "        'C': (0.01, 0.05, 0.1, 0.25, 0.5, 1)\n",
    "    },\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gs3_b.fit(X3_train_scaled_some, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980848153214774"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3_b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3_b.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9139344262295082"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3_b.score(X3_test_scaled_some, y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling only the columns that were not one-hot-encoded or from a count vectorizer resulted in a slightly stronger prediction from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the logistic regression is the best performing model with this information. Below I will try using some naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb3 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val Scores: [0.82786885 0.82377049 0.74897119]\n",
      "Avg Cross-val Score: 0.8002035125593109\n"
     ]
    }
   ],
   "source": [
    "nb3_scores = cross_val_score(nb3, X3_train, y3_train)\n",
    "print('Cross-val Scores:', nb3_scores)\n",
    "print('Avg Cross-val Score:', nb3_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8454172366621067\n",
      "0.7848360655737705\n"
     ]
    }
   ],
   "source": [
    "nb3.fit(X3_train, y3_train)\n",
    "print(nb3.score(X3_train, y3_train))\n",
    "print(nb3.score(X3_test, y3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_scores.append(nb3.score(X3_test, y3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive bayes has improved, but is still overfit and is not nearly as strong as the logistic regression model. This is likely because there are more than just text features in the data and there is no regularization being used in naive bayes. Since there are so many features, this is becoming a high variance model, but since the accuracy is so low, decreasing bias by increasing variance does not seem worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>0.743852</td>\n",
       "      <td>0.702869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>0.747951</td>\n",
       "      <td>0.774590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>0.784836</td>\n",
       "      <td>0.905738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Naive Bayes  Logistic Regression\n",
       "Model 1     0.743852             0.702869\n",
       "Model 2     0.747951             0.774590\n",
       "Model 3     0.784836             0.905738"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = pd.DataFrame([nb_scores, log_scores],\n",
    "             index=['Naive Bayes', 'Logistic Regression'],\n",
    "             columns=['Model 1', 'Model 2', 'Model 3'])\n",
    "model_scores = model_scores.T\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores['Naive Bayes Net'] = [0,\n",
    "                                   model_scores.iloc[1,0] - model_scores.iloc[0,0],\n",
    "                                   model_scores.iloc[2,0] - model_scores.iloc[1,0]]\n",
    "\n",
    "model_scores['Logistic Regression Net'] = [0,\n",
    "                                           model_scores.iloc[1,1]-model_scores.iloc[0,1],\n",
    "                                           model_scores.iloc[2,1]-model_scores.iloc[1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores.to_csv('./Assets/model_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores['nb_water'] = [0, model_scores.iloc[0,0], model_scores.iloc[1, 0]]\n",
    "model_scores['nb_water_top'] = [model_scores.iloc[0,0], model_scores.iloc[1, 2], model_scores.iloc[2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Naive Bayes Net</th>\n",
       "      <th>Logistic Regression Net</th>\n",
       "      <th>nb_water</th>\n",
       "      <th>nb_water_top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>0.743852</td>\n",
       "      <td>0.702869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.743852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>0.747951</td>\n",
       "      <td>0.774590</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.071721</td>\n",
       "      <td>0.743852</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>0.784836</td>\n",
       "      <td>0.905738</td>\n",
       "      <td>0.036885</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.747951</td>\n",
       "      <td>0.036885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Naive Bayes  Logistic Regression  Naive Bayes Net  \\\n",
       "Model 1     0.743852             0.702869         0.000000   \n",
       "Model 2     0.747951             0.774590         0.004098   \n",
       "Model 3     0.784836             0.905738         0.036885   \n",
       "\n",
       "         Logistic Regression Net  nb_water  nb_water_top  \n",
       "Model 1                 0.000000  0.000000      0.743852  \n",
       "Model 2                 0.071721  0.743852      0.004098  \n",
       "Model 3                 0.131148  0.747951      0.036885  "
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "model_scores[['nb_water', 'nb_water_top']].plot(kind='bar', stacked=True, legend=False, ax=ax,\n",
    "                                                figsize=(10,10), color = ['w', 'blue'], alpha=0.6,\n",
    "                                                title=\"Naive Bayes Showed Minimal Improvement with New Features\",\n",
    "                                                layout='tight')\n",
    "plt.xticks(size=15, alpha=0.7)\n",
    "plt.yticks([])\n",
    "plt.title('Naive Bayes Showed Minimal Improvement', size=22, position=(0,1), ha='left')\n",
    "for item in ['left', 'right', 'top', 'bottom']:\n",
    "    ax.spines[item].set_visible(False)\n",
    "plt.plot([0, 1], [model_scores.loc['Model 1','Naive Bayes'],model_scores.loc['Model 1','Naive Bayes']],\n",
    "         'r', lw=1.5, alpha=0.5)\n",
    "plt.plot([1, 2], [model_scores.loc['Model 2','Naive Bayes'],model_scores.loc['Model 2','Naive Bayes']],\n",
    "         'r', lw=1.5, alpha=0.5)\n",
    "for i in range(3):\n",
    "    plt.text(i, model_scores.iloc[i, 0]+.02, str(round(100*model_scores.iloc[i,0],1))+'%', ha='center', size=18)\n",
    "\n",
    "plt.text(0.5, 0.7, '+' + str(round(100*model_scores.iloc[1,2],2)) + '%', size=12, alpha=0.7, ha='center')\n",
    "plt.text(1.5, 0.71, '+' + str(round(100*model_scores.iloc[2,2],2)) + '%', size=12, alpha=0.7, ha='center')\n",
    "plt.savefig('./Assets/nb_waterfall.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores['log_water'] = [0, model_scores.iloc[0,1], model_scores.iloc[1, 1]]\n",
    "model_scores['log_water_top'] = [model_scores.iloc[0,1], model_scores.iloc[1, 3], model_scores.iloc[2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "model_scores[['log_water', 'log_water_top']].plot(kind='bar', stacked=True, legend=False, ax=ax,\n",
    "                                                figsize=(10,10), color = ['w', 'green'], alpha=0.6,\n",
    "                                                layout='tight')\n",
    "plt.xticks(size=15, alpha=0.7)\n",
    "plt.yticks([])\n",
    "plt.title('Logistic Regression Helped by Numerical Features', size=22, position=(0,1), ha='left')\n",
    "for item in ['left', 'right', 'top', 'bottom']:\n",
    "    ax.spines[item].set_visible(False)\n",
    "plt.plot([0, 1], [model_scores.loc['Model 1','Logistic Regression'],model_scores.loc['Model 1','Logistic Regression']],\n",
    "         'r', lw=1.5, alpha=0.5)\n",
    "plt.plot([1, 2], [model_scores.loc['Model 2','Logistic Regression'],model_scores.loc['Model 2','Logistic Regression']],\n",
    "         'r', lw=1.5, alpha=0.5)\n",
    "for i in range(3):\n",
    "    plt.text(i, model_scores.iloc[i, 1]+.02, str(round(100*model_scores.iloc[i,1],1))+'%', ha='center', size=18)\n",
    "\n",
    "plt.text(0.5, 0.67, '+' + str(round(100*model_scores.iloc[1,3],2)) + '%', size=12, alpha=0.7, ha='center')\n",
    "plt.text(1.5, 0.74, '+' + str(round(100*model_scores.iloc[2,3],2)) + '%', size=12, alpha=0.7, ha='center')\n",
    "plt.savefig('./Assets/logreg_waterfall.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: everything except comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['archived', 'comments', 'domain', 'downs', 'gilded',\n",
       "       'is_reddit_media_domain', 'is_self', 'is_video', 'num_comments',\n",
       "       'num_crossposts', 'score', 'selftext', 'send_replies', 'subreddit',\n",
       "       'title', 'ups', 'flair_text', 'post_hint_image', 'post_hint_link',\n",
       "       'post_hint_rich:video', 'post_hint_self'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archived',\n",
       " 'domain',\n",
       " 'downs',\n",
       " 'gilded',\n",
       " 'is_reddit_media_domain',\n",
       " 'is_self',\n",
       " 'is_video',\n",
       " 'num_comments',\n",
       " 'num_crossposts',\n",
       " 'score',\n",
       " 'selftext',\n",
       " 'send_replies',\n",
       " 'title',\n",
       " 'ups',\n",
       " 'flair_text',\n",
       " 'post_hint_image',\n",
       " 'post_hint_link',\n",
       " 'post_hint_rich:video',\n",
       " 'post_hint_self']"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features4 = [col for col in red_df.columns if col not in ['comments', 'subreddit']]\n",
    "features4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = red_df[features4]\n",
    "y4 = red_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = pd.concat([X4.drop('domain', axis=1), pd.get_dummies(X4['domain'], prefix='domain_', drop_first=True)],\n",
    "          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['archived', 'downs', 'gilded', 'is_reddit_media_domain', 'is_self',\n",
       "       'is_video', 'num_comments', 'num_crossposts', 'score', 'selftext',\n",
       "       ...\n",
       "       'domain__whitehouse', 'domain__wikimedia', 'domain__wikipedia',\n",
       "       'domain__wpengine', 'domain__wsj', 'domain__yahoo', 'domain__youtu',\n",
       "       'domain__youtube', 'domain__zerohedge', 'domain__zimbio'],\n",
       "      dtype='object', length=196)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, there are multiple columns that I would like to vectorize. Instead of manually doing this, I will use the classes in the next two cells as well as the FeatureUnion class in order to create a pipeline that will programatically deal with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column names to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if len(self.vars) > 1:\n",
    "            return pd.DataFrame(X[self.vars]) # where the actual feature extraction happens\n",
    "        else:\n",
    "            return pd.Series(X[self.vars[0]])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "class DenseTransformer(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "#         print X.todense()\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['selftext', 'title', 'flair_text'], dtype='object')"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'archived': 'feature_archived',\n",
       " 'downs': 'feature_downs',\n",
       " 'gilded': 'feature_gilded',\n",
       " 'is_reddit_media_domain': 'feature_is_reddit_media_domain',\n",
       " 'is_self': 'feature_is_self',\n",
       " 'is_video': 'feature_is_video',\n",
       " 'num_comments': 'feature_num_comments',\n",
       " 'num_crossposts': 'feature_num_crossposts',\n",
       " 'score': 'feature_score',\n",
       " 'send_replies': 'feature_send_replies',\n",
       " 'ups': 'feature_ups'}"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_renamer = {}\n",
    "for col in X4.select_dtypes(\"int64\").columns:\n",
    "    col_renamer[col] = 'feature_' + col\n",
    "\n",
    "col_renamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4.rename(mapper=col_renamer, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_archived', 'feature_downs', 'feature_gilded',\n",
       "       'feature_is_reddit_media_domain', 'feature_is_self', 'feature_is_video',\n",
       "       'feature_num_comments', 'feature_num_crossposts', 'feature_score',\n",
       "       'selftext',\n",
       "       ...\n",
       "       'domain__whitehouse', 'domain__wikimedia', 'domain__wikipedia',\n",
       "       'domain__wpengine', 'domain__wsj', 'domain__yahoo', 'domain__youtu',\n",
       "       'domain__youtube', 'domain__zerohedge', 'domain__zimbio'],\n",
       "      dtype='object', length=196)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cols = [col for col in X4.columns if col not in ['selftext', 'title', 'flair_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial pipeline\n",
    "pipe4 = Pipeline([\n",
    "    \n",
    "    # First step is feature union. This will concatenate the dataframes returned below\n",
    "    ('features', FeatureUnion([\n",
    "        \n",
    "        # Create pipeline for selftext column\n",
    "        ('selftext', Pipeline([\n",
    "            \n",
    "            # Pull out just the selftext column\n",
    "            ('text', SampleExtractor(['selftext'])),\n",
    "            \n",
    "            # Count vectorize just the selftext column\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            \n",
    "            # Convert sparse matrix to dense matrix\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "        \n",
    "        # Create pipeline for title column and follow same steps as above\n",
    "        ('title', Pipeline([\n",
    "            ('text', SampleExtractor(['title'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "        \n",
    "        # Create pipeline for flair_text column and follow same steps as above\n",
    "        ('flair_text', Pipeline([\n",
    "            ('text', SampleExtractor(['flair_text'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "        \n",
    "        # Create pipeline for all other columns and just select the variables\n",
    "        ('other', Pipeline([\n",
    "            ('text', SampleExtractor(other_cols))\n",
    "        ]))\n",
    "        \n",
    "    ])),\n",
    "    ('ss', StandardScaler()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params4 = {\n",
    "    'logreg__penalty': ('l1', 'l2'),\n",
    "    'logreg__C': (0.25, 0.275, 0.3)\n",
    "}\n",
    "\n",
    "gs4 = GridSearchCV(pipe4, grid_params4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   19.9s finished\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('selftext', Pipeline(memory=None,\n",
       "     steps=[('text', SampleExtractor(vars=['selftext'])), ('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logreg__penalty': ('l1', 'l2'), 'logreg__C': (0.25, 0.275, 0.3)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896032831737346"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 0.25, 'logreg__penalty': 'l1'}"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9972640218878249"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.score(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9118852459016393"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.score(X4_test, y4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, adding the additional infomration did not seem to help. I'm going to try doing this again by only scaling those features which are not 1 hot encoded and also not from the vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_cols4 = list(X4.select_dtypes('uint8').columns)\n",
    "len(dummy_cols4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_archived',\n",
       " 'feature_downs',\n",
       " 'feature_gilded',\n",
       " 'feature_is_reddit_media_domain',\n",
       " 'feature_is_self',\n",
       " 'feature_is_video',\n",
       " 'feature_num_comments',\n",
       " 'feature_num_crossposts',\n",
       " 'feature_score',\n",
       " 'selftext',\n",
       " 'feature_send_replies',\n",
       " 'title',\n",
       " 'feature_ups',\n",
       " 'flair_text']"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in X4.columns if col not in dummy_cols4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols4 = ['feature_archived', 'feature_downs', 'feature_gilded', 'feature_num_comments', \n",
    "               'feature_num_crossposts', 'feature_score', 'feature_ups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder_cols = [col for col in other_cols if col not in scale_cols4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe4_some_scale =  Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        # Create pipeline for selftext column\n",
    "        ('selftext', Pipeline([\n",
    "\n",
    "            # Pull out just the selftext column\n",
    "            ('text', SampleExtractor(['selftext'])),\n",
    "\n",
    "            # Count vectorize just the selftext column\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "\n",
    "            # Convert sparse matrix to dense matrix\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for title column and follow same steps as above\n",
    "        ('title', Pipeline([\n",
    "            ('text', SampleExtractor(['title'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for flair_text column and follow same steps as above\n",
    "        ('flair_text', Pipeline([\n",
    "            ('text', SampleExtractor(['flair_text'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for the remaining columns\n",
    "        ('remaining', Pipeline([\n",
    "            ('text', SampleExtractor(remainder_cols))\n",
    "        ])),\n",
    "        \n",
    "        ('scale', Pipeline([\n",
    "            ('text', SampleExtractor(scale_cols4)),\n",
    "            ('ss', StandardScaler())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('logreg', LogisticRegression(verbose=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:898: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('selftext', Pipeline(memory=None,\n",
       "     steps=[('text', SampleExtractor(vars=['selftext'])), ('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logreg__C': (0.01, 0.2575, 0.505, 0.7525, 1.0), 'logreg__penalty': ('l1', 'l2'), 'features__selftext__cv__ngram_range': ((1, 1), (1, 2)), 'features__title__cv__ngram_range': ((1, 1), (1, 2), (1, 3)), 'features__flair_text__cv__ngram_range': ((1, 1), (1, 2), (1, 3))},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_val4 = tuple(np.linspace(0.01, 1, 5))\n",
    "grid_params4_scale = {\n",
    "    'logreg__C': C_val4,\n",
    "    'logreg__penalty': ('l1', 'l2'),\n",
    "    'features__selftext__cv__ngram_range': ((1,1), (1,2)),\n",
    "    'features__title__cv__ngram_range': ((1,1),(1,2),(1,3)),\n",
    "    'features__flair_text__cv__ngram_range': ((1,1),(1,2),(1,3))\n",
    "}\n",
    "\n",
    "gs4_some_scale = GridSearchCV(pipe4_some_scale, grid_params4_scale, verbose=1)\n",
    "\n",
    "gs4_some_scale.fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8967168262653898"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_some_scale_scale.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features__flair_text__cv__ngram_range': (1, 1),\n",
       " 'features__selftext__cv__ngram_range': (1, 1),\n",
       " 'features__title__cv__ngram_range': (1, 1),\n",
       " 'logreg__C': 0.505,\n",
       " 'logreg__penalty': 'l2'}"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_some_scale.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9200819672131147"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_some_scale.score(X4_test, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we have a slight improvement, but we still have room to grow. The last piece that we can include is the comments. This will result in a much larger model that will take significantly longer to fit, so first I'm going to try some bagging models using logistic regression, decision trees, and naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Models expanding upon Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bag = Pipeline([(\n",
    "    'features', FeatureUnion([\n",
    "        # Create pipeline for selftext column\n",
    "        ('selftext', Pipeline([\n",
    "\n",
    "            # Pull out just the selftext column\n",
    "            ('text', SampleExtractor(['selftext'])),\n",
    "\n",
    "            # Count vectorize just the selftext column\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "\n",
    "            # Convert sparse matrix to dense matrix\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for title column and follow same steps as above\n",
    "        ('title', Pipeline([\n",
    "            ('text', SampleExtractor(['title'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for flair_text column and follow same steps as above\n",
    "        ('flair_text', Pipeline([\n",
    "            ('text', SampleExtractor(['flair_text'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for the remaining columns\n",
    "        ('remaining', Pipeline([\n",
    "            ('text', SampleExtractor(remainder_cols))\n",
    "        ])),\n",
    "        \n",
    "        ('scale', Pipeline([\n",
    "            ('text', SampleExtractor(scale_cols4)),\n",
    "            ('ss', StandardScaler())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('bag', BaggingClassifier(DecisionTreeClassifier()))\n",
    "])\n",
    "\n",
    "bag_grid_params = {\n",
    "    'bag__base_estimator__criterion': ('gini', 'entropy'),\n",
    "    'bag__n_estimators': (10, 25, 50, 55, 65, 75),\n",
    "}\n",
    "gs_bag = GridSearchCV(pipe_bag, bag_grid_params, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('selftext', Pipeline(memory=None,\n",
       "     steps=[('text', SampleExtractor(vars=['selftext'])), ('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'bag__base_estimator__criterion': ('gini', 'entropy'), 'bag__n_estimators': (10, 25, 50, 55, 65, 75)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag.fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9548563611491108"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__base_estimator__criterion': 'entropy', 'bag__n_estimators': 25}"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986320109439124"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag.score(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344262295081968"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag.score(X4_test, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df['comments'] = red_df['comments'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(red_df['comments'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = X4.copy()\n",
    "X5['comments'] = red_df['comments']\n",
    "y5 = red_df['subreddit']\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5 = Pipeline([(\n",
    "    'features', FeatureUnion([\n",
    "        # Create pipeline for selftext column\n",
    "        ('selftext', Pipeline([\n",
    "\n",
    "            # Pull out just the selftext column\n",
    "            ('text', SampleExtractor(['selftext'])),\n",
    "\n",
    "            # Count vectorize just the selftext column\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "\n",
    "            # Convert sparse matrix to dense matrix\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for title column and follow same steps as above\n",
    "        ('title', Pipeline([\n",
    "            ('text', SampleExtractor(['title'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for flair_text column and follow same steps as above\n",
    "        ('flair_text', Pipeline([\n",
    "            ('text', SampleExtractor(['flair_text'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "        \n",
    "        # Create pipeline for comments column\n",
    "        ('comments', Pipeline([\n",
    "            ('text', SampleExtractor(['comments'])),\n",
    "            ('cv', CountVectorizer(stop_words=stops, max_features=25000)),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for the remaining columns\n",
    "        ('remaining', Pipeline([\n",
    "            ('text', SampleExtractor(remainder_cols))\n",
    "        ])),\n",
    "        \n",
    "        ('scale', Pipeline([\n",
    "            ('text', SampleExtractor(scale_cols4)),\n",
    "            ('ss', StandardScaler())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('bag', BaggingClassifier(DecisionTreeClassifier(), n_estimators=25))\n",
    "])\n",
    "\n",
    "grid_params5 = {\n",
    "    'bag__base_estimator__max_depth': (10, 15)\n",
    "}\n",
    "gs5 = GridSearchCV(pipe5, grid_params5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('selftext', Pipeline(memory=None,\n",
       "     steps=[('text', SampleExtractor(vars=['selftext'])), ('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...estimators=25, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'bag__base_estimator__max_depth': (10, 15)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5.fit(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822161422708618"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__n_estimators': 25}"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5.score(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774590163934426"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5.score(X5_test, y5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5_logreg = Pipeline([(\n",
    "    'features', FeatureUnion([\n",
    "        # Create pipeline for selftext column\n",
    "        ('selftext', Pipeline([\n",
    "\n",
    "            # Pull out just the selftext column\n",
    "            ('text', SampleExtractor(['selftext'])),\n",
    "\n",
    "            # Count vectorize just the selftext column\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "\n",
    "            # Convert sparse matrix to dense matrix\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for title column and follow same steps as above\n",
    "        ('title', Pipeline([\n",
    "            ('text', SampleExtractor(['title'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for flair_text column and follow same steps as above\n",
    "        ('flair_text', Pipeline([\n",
    "            ('text', SampleExtractor(['flair_text'])),\n",
    "            ('cv', CountVectorizer(stop_words='english')),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "        \n",
    "        # Create pipeline for comments column\n",
    "        ('comments', Pipeline([\n",
    "            ('text', SampleExtractor(['comments'])),\n",
    "            ('cv', CountVectorizer(stop_words=stops)),\n",
    "            ('dense', DenseTransformer())\n",
    "        ])),\n",
    "\n",
    "        # Create pipeline for the remaining columns\n",
    "        ('remaining', Pipeline([\n",
    "            ('text', SampleExtractor(remainder_cols))\n",
    "        ])),\n",
    "        \n",
    "        ('scale', Pipeline([\n",
    "            ('text', SampleExtractor(scale_cols4)),\n",
    "            ('ss', StandardScaler())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('logreg_bag', BaggingClassifier(base_estimator = LogisticRegression(verbose=1), verbose=1))\n",
    "])\n",
    "\n",
    "grid_params5_logreg = {\n",
    "    'features__comments__cv__max_features': (15000, 25000, 35000),\n",
    "    'features__comments__cv__ngram_range': ((1, 2), (1, 3)),\n",
    "    'logreg_bag__base_estimator__C': (0.05, 0.075),\n",
    "    'logreg_bag__base_estimator__penalty': ('l1', 'l2')\n",
    "}\n",
    "gs5_logreg = GridSearchCV(pipe5_logreg, grid_params5_logreg, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 27.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('selftext', Pipeline(memory=None,\n",
       "     steps=[('text', SampleExtractor(vars=['selftext'])), ('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=1, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'features__comments__cv__max_features': (15000, 25000, 35000), 'features__comments__cv__ngram_range': ((1, 2), (1, 3)), 'logreg_bag__base_estimator__C': (0.05, 0.075), 'logreg_bag__base_estimator__penalty': ('l1', 'l2')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5_logreg.fit(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740082079343365"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5_logreg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features__comments__cv__max_features': 25000,\n",
       " 'features__comments__cv__ngram_range': (1, 3),\n",
       " 'logreg_bag__base_estimator__C': 0.05,\n",
       " 'logreg_bag__base_estimator__penalty': 'l2'}"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9713114754098361"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5_logreg.score(X5_test, y5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg_bag__base_estimator__C': 0.01,\n",
       " 'logreg_bag__base_estimator__penalty': 'l2'}"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774590163934426"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5_logreg.score(X5_test, y5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments Only Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_com = red_df['comments']\n",
    "y_com = red_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_com_train, X_com_test, y_com_train, y_com_test = train_test_split(X_com, y_com, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_finder_cv = CountVectorizer()\n",
    "num_finder_cv.fit(X_com_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2442"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in num_finder_cv.get_feature_names():\n",
    "    if col.isnumeric():\n",
    "        stops.add(col)\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56635"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_finder_cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('vect', CountVectorizer(stop_words = stops)),\n",
    "         ('nb', MultinomialNB())]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid_params = {\n",
    "    'vect__max_features': (15000, 25000, 35000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'vect__token_pattern': ('r\\\\/\\\\w+|[a-zA-Z]+|[\\\\d\\\\.\\\\,]+|[\\\\.\\\\?\\\\!\\\\,]+\\\\S', '(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "}\n",
    "\n",
    "grid_4 = GridSearchCV(pipe, grid_params, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed: 38.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'even', '1...kenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_features': (15000, 25000, 35000), 'vect__ngram_range': ((1, 1), (1, 2), (1, 3)), 'vect__token_pattern': ('r\\\\/\\\\w+|[a-zA-Z]+|[\\\\d\\\\.\\\\,]+|[\\\\.\\\\?\\\\!\\\\,]+\\\\S', '(?u)\\\\b\\\\w\\\\w+\\\\b')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_4.fit(X_com_train, y_com_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9233926128590971"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__max_features': 15000,\n",
       " 'vect__ngram_range': (1, 3),\n",
       " 'vect__token_pattern': 'r\\\\/\\\\w+|[a-zA-Z]+|[\\\\d\\\\.\\\\,]+|[\\\\.\\\\?\\\\!\\\\,]+\\\\S'}"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.944672131147541"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_4.score(X_com_test, y_com_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('vect', CountVectorizer(stop_words=stops)),\n",
    "         ('logreg', LogisticRegression())]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid_params = {\n",
    "    'vect__max_features': (10000, 25000),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),\n",
    "    'vect__token_pattern': ('r\\\\/\\\\w+|[a-zA-Z]+|[\\\\d\\\\.\\\\,]+|[\\\\.\\\\?\\\\!\\\\,]+\\\\S', '(?u)\\\\b\\\\w\\\\w+\\\\b'),\n",
    "    'logreg__C': (0.1, 0.5)\n",
    "}\n",
    "\n",
    "grid_5 = GridSearchCV(pipe, grid_params, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'even', '1...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_features': (10000, 25000), 'vect__ngram_range': ((1, 2), (1, 3)), 'vect__token_pattern': ('r\\\\/\\\\w+|[a-zA-Z]+|[\\\\d\\\\.\\\\,]+|[\\\\.\\\\?\\\\!\\\\,]+\\\\S', '(?u)\\\\b\\\\w\\\\w+\\\\b'), 'logreg__C': (0.1, 0.5)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_5.fit(X_com_train, y_com_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746922024623803"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 0.1,\n",
       " 'vect__max_features': 10000,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__token_pattern': 'r\\\\/\\\\w+|[a-zA-Z]+|[\\\\d\\\\.\\\\,]+|[\\\\.\\\\?\\\\!\\\\,]+\\\\S'}"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9672131147540983"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_5.score(X_com_test, y_com_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So predicting based just off of title and self-text is quite difficult to actually do. Even with tweaking hyperparameters, trying different tokenizers, the best accuracy I could get on the testing set was 75%. When I used the comments based model, my accuracy greatly increased. The maximum accuracy score jumped up to 97.7%, which is extremely accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13697669],\n",
       "       [-0.00076557],\n",
       "       [-0.004454  ],\n",
       "       ...,\n",
       "       [ 0.00288545],\n",
       "       [-0.0022731 ],\n",
       "       [-0.0016054 ]])"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_5.best_estimator_.get_params()['steps'][1][1].coef_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(data=grid_5.best_estimator_.get_params()['steps'][1][1].coef_.T,\n",
    "                            index = grid_5.best_estimator_.get_params()['steps'][0][1].get_feature_names())\n",
    "coefficients.head()\n",
    "coefficients.columns=['Coefficient']\n",
    "coefficients['abs'] = abs(coefficients['Coefficient'])\n",
    "coefficients['sign'] = coefficients['Coefficient'] > 0\n",
    "coefficients.to_csv('./Assets/coefficients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>abs</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kek</th>\n",
       "      <td>-0.270937</td>\n",
       "      <td>0.270937</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media</th>\n",
       "      <td>-0.268474</td>\n",
       "      <td>0.268474</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberals</th>\n",
       "      <td>-0.260590</td>\n",
       "      <td>0.260590</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mueller</th>\n",
       "      <td>0.255132</td>\n",
       "      <td>0.255132</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>-0.250680</td>\n",
       "      <td>0.250680</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hillary</th>\n",
       "      <td>-0.239570</td>\n",
       "      <td>0.239570</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>-0.234417</td>\n",
       "      <td>0.234417</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>0.222023</td>\n",
       "      <td>0.222023</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>republicans</th>\n",
       "      <td>0.219221</td>\n",
       "      <td>0.219221</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>-0.198342</td>\n",
       "      <td>0.198342</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https</th>\n",
       "      <td>0.196423</td>\n",
       "      <td>0.196423</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>republican</th>\n",
       "      <td>0.191249</td>\n",
       "      <td>0.191249</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub</th>\n",
       "      <td>0.178761</td>\n",
       "      <td>0.178761</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geotus</th>\n",
       "      <td>-0.173902</td>\n",
       "      <td>0.173902</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guilty</th>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maga</th>\n",
       "      <td>-0.164972</td>\n",
       "      <td>0.164972</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removed</th>\n",
       "      <td>-0.164494</td>\n",
       "      <td>0.164494</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gop</th>\n",
       "      <td>0.164102</td>\n",
       "      <td>0.164102</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muh</th>\n",
       "      <td>-0.155946</td>\n",
       "      <td>0.155946</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>administration</th>\n",
       "      <td>0.153353</td>\n",
       "      <td>0.153353</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hope</th>\n",
       "      <td>0.151132</td>\n",
       "      <td>0.151132</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>-0.149461</td>\n",
       "      <td>0.149461</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>-0.145608</td>\n",
       "      <td>0.145608</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msm</th>\n",
       "      <td>-0.144774</td>\n",
       "      <td>0.144774</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bernie</th>\n",
       "      <td>-0.144729</td>\n",
       "      <td>0.144729</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>podesta</th>\n",
       "      <td>-0.144260</td>\n",
       "      <td>0.144260</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.143517</td>\n",
       "      <td>0.143517</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>-0.143340</td>\n",
       "      <td>0.143340</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swamp</th>\n",
       "      <td>-0.141474</td>\n",
       "      <td>0.141474</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedes</th>\n",
       "      <td>-0.137908</td>\n",
       "      <td>0.137908</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dems</th>\n",
       "      <td>-0.136993</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!</th>\n",
       "      <td>-0.136977</td>\n",
       "      <td>0.136977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supporters</th>\n",
       "      <td>0.135833</td>\n",
       "      <td>0.135833</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohen</th>\n",
       "      <td>0.132501</td>\n",
       "      <td>0.132501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>-0.129367</td>\n",
       "      <td>0.129367</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>-0.128210</td>\n",
       "      <td>0.128210</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>based</th>\n",
       "      <td>-0.125095</td>\n",
       "      <td>0.125095</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>0.119213</td>\n",
       "      <td>0.119213</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spez</th>\n",
       "      <td>-0.118551</td>\n",
       "      <td>0.118551</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>-0.118131</td>\n",
       "      <td>0.118131</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>draft</th>\n",
       "      <td>0.116804</td>\n",
       "      <td>0.116804</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spicy</th>\n",
       "      <td>-0.116691</td>\n",
       "      <td>0.116691</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuck</th>\n",
       "      <td>-0.115854</td>\n",
       "      <td>0.115854</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>office</th>\n",
       "      <td>0.114546</td>\n",
       "      <td>0.114546</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>putin</th>\n",
       "      <td>0.114323</td>\n",
       "      <td>0.114323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needs</th>\n",
       "      <td>-0.112284</td>\n",
       "      <td>0.112284</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archive</th>\n",
       "      <td>-0.112027</td>\n",
       "      <td>0.112027</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edit</th>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redacted</th>\n",
       "      <td>-0.111399</td>\n",
       "      <td>0.111399</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pede</th>\n",
       "      <td>-0.111394</td>\n",
       "      <td>0.111394</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coefficient       abs   sign\n",
       "kek                -0.270937  0.270937  False\n",
       "media              -0.268474  0.268474  False\n",
       "liberals           -0.260590  0.260590  False\n",
       "mueller             0.255132  0.255132   True\n",
       "left               -0.250680  0.250680  False\n",
       "hillary            -0.239570  0.239570  False\n",
       "cnn                -0.234417  0.234417  False\n",
       "trump               0.222023  0.222023   True\n",
       "republicans         0.219221  0.219221   True\n",
       "love               -0.198342  0.198342  False\n",
       "https               0.196423  0.196423   True\n",
       "republican          0.191249  0.191249   True\n",
       "sub                 0.178761  0.178761   True\n",
       "geotus             -0.173902  0.173902  False\n",
       "guilty              0.167608  0.167608   True\n",
       "maga               -0.164972  0.164972  False\n",
       "removed            -0.164494  0.164494  False\n",
       "gop                 0.164102  0.164102   True\n",
       "muh                -0.155946  0.155946  False\n",
       "administration      0.153353  0.153353   True\n",
       "hope                0.151132  0.151132   True\n",
       "years              -0.149461  0.149461  False\n",
       "liberal            -0.145608  0.145608  False\n",
       "msm                -0.144774  0.144774  False\n",
       "bernie             -0.144729  0.144729  False\n",
       "podesta            -0.144260  0.144260  False\n",
       "fox                 0.143517  0.143517   True\n",
       "president trump    -0.143340  0.143340  False\n",
       "swamp              -0.141474  0.141474  False\n",
       "pedes              -0.137908  0.137908  False\n",
       "dems               -0.136993  0.136993  False\n",
       "!!                 -0.136977  0.136977  False\n",
       "supporters          0.135833  0.135833   True\n",
       "cohen               0.132501  0.132501   True\n",
       "post               -0.129367  0.129367  False\n",
       "comments           -0.128210  0.128210  False\n",
       "based              -0.125095  0.125095  False\n",
       "white house         0.119213  0.119213   True\n",
       "spez               -0.118551  0.118551  False\n",
       "president          -0.118131  0.118131  False\n",
       "draft               0.116804  0.116804   True\n",
       "spicy              -0.116691  0.116691  False\n",
       "cuck               -0.115854  0.115854  False\n",
       "office              0.114546  0.114546   True\n",
       "putin               0.114323  0.114323   True\n",
       "needs              -0.112284  0.112284  False\n",
       "archive            -0.112027  0.112027  False\n",
       "edit                0.111618  0.111618   True\n",
       "redacted           -0.111399  0.111399  False\n",
       "pede               -0.111394  0.111394  False"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients.sort_values('abs', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>abs</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kek</th>\n",
       "      <td>-0.270937</td>\n",
       "      <td>0.270937</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media</th>\n",
       "      <td>-0.268474</td>\n",
       "      <td>0.268474</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberals</th>\n",
       "      <td>-0.260590</td>\n",
       "      <td>0.260590</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>-0.250680</td>\n",
       "      <td>0.250680</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hillary</th>\n",
       "      <td>-0.239570</td>\n",
       "      <td>0.239570</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>-0.234417</td>\n",
       "      <td>0.234417</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>-0.198342</td>\n",
       "      <td>0.198342</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geotus</th>\n",
       "      <td>-0.173902</td>\n",
       "      <td>0.173902</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maga</th>\n",
       "      <td>-0.164972</td>\n",
       "      <td>0.164972</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removed</th>\n",
       "      <td>-0.164494</td>\n",
       "      <td>0.164494</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muh</th>\n",
       "      <td>-0.155946</td>\n",
       "      <td>0.155946</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>-0.149461</td>\n",
       "      <td>0.149461</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>-0.145608</td>\n",
       "      <td>0.145608</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msm</th>\n",
       "      <td>-0.144774</td>\n",
       "      <td>0.144774</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bernie</th>\n",
       "      <td>-0.144729</td>\n",
       "      <td>0.144729</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>podesta</th>\n",
       "      <td>-0.144260</td>\n",
       "      <td>0.144260</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>-0.143340</td>\n",
       "      <td>0.143340</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swamp</th>\n",
       "      <td>-0.141474</td>\n",
       "      <td>0.141474</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedes</th>\n",
       "      <td>-0.137908</td>\n",
       "      <td>0.137908</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dems</th>\n",
       "      <td>-0.136993</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!</th>\n",
       "      <td>-0.136977</td>\n",
       "      <td>0.136977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>-0.129367</td>\n",
       "      <td>0.129367</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>-0.128210</td>\n",
       "      <td>0.128210</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>based</th>\n",
       "      <td>-0.125095</td>\n",
       "      <td>0.125095</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spez</th>\n",
       "      <td>-0.118551</td>\n",
       "      <td>0.118551</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coefficient       abs   sign\n",
       "kek                -0.270937  0.270937  False\n",
       "media              -0.268474  0.268474  False\n",
       "liberals           -0.260590  0.260590  False\n",
       "left               -0.250680  0.250680  False\n",
       "hillary            -0.239570  0.239570  False\n",
       "cnn                -0.234417  0.234417  False\n",
       "love               -0.198342  0.198342  False\n",
       "geotus             -0.173902  0.173902  False\n",
       "maga               -0.164972  0.164972  False\n",
       "removed            -0.164494  0.164494  False\n",
       "muh                -0.155946  0.155946  False\n",
       "years              -0.149461  0.149461  False\n",
       "liberal            -0.145608  0.145608  False\n",
       "msm                -0.144774  0.144774  False\n",
       "bernie             -0.144729  0.144729  False\n",
       "podesta            -0.144260  0.144260  False\n",
       "president trump    -0.143340  0.143340  False\n",
       "swamp              -0.141474  0.141474  False\n",
       "pedes              -0.137908  0.137908  False\n",
       "dems               -0.136993  0.136993  False\n",
       "!!                 -0.136977  0.136977  False\n",
       "post               -0.129367  0.129367  False\n",
       "comments           -0.128210  0.128210  False\n",
       "based              -0.125095  0.125095  False\n",
       "spez               -0.118551  0.118551  False"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients[coefficients['sign']==False].sort_values('abs', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>abs</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mueller</th>\n",
       "      <td>0.255132</td>\n",
       "      <td>0.255132</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>0.222023</td>\n",
       "      <td>0.222023</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>republicans</th>\n",
       "      <td>0.219221</td>\n",
       "      <td>0.219221</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https</th>\n",
       "      <td>0.196423</td>\n",
       "      <td>0.196423</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>republican</th>\n",
       "      <td>0.191249</td>\n",
       "      <td>0.191249</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub</th>\n",
       "      <td>0.178761</td>\n",
       "      <td>0.178761</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guilty</th>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gop</th>\n",
       "      <td>0.164102</td>\n",
       "      <td>0.164102</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>administration</th>\n",
       "      <td>0.153353</td>\n",
       "      <td>0.153353</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hope</th>\n",
       "      <td>0.151132</td>\n",
       "      <td>0.151132</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.143517</td>\n",
       "      <td>0.143517</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supporters</th>\n",
       "      <td>0.135833</td>\n",
       "      <td>0.135833</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohen</th>\n",
       "      <td>0.132501</td>\n",
       "      <td>0.132501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>0.119213</td>\n",
       "      <td>0.119213</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>draft</th>\n",
       "      <td>0.116804</td>\n",
       "      <td>0.116804</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>office</th>\n",
       "      <td>0.114546</td>\n",
       "      <td>0.114546</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>putin</th>\n",
       "      <td>0.114323</td>\n",
       "      <td>0.114323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edit</th>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert</th>\n",
       "      <td>0.109766</td>\n",
       "      <td>0.109766</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justice</th>\n",
       "      <td>0.108287</td>\n",
       "      <td>0.108287</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donnie</th>\n",
       "      <td>0.103060</td>\n",
       "      <td>0.103060</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>0.103038</td>\n",
       "      <td>0.103038</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emails</th>\n",
       "      <td>0.102886</td>\n",
       "      <td>0.102886</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.101725</td>\n",
       "      <td>0.101725</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war</th>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Coefficient       abs  sign\n",
       "mueller            0.255132  0.255132  True\n",
       "trump              0.222023  0.222023  True\n",
       "republicans        0.219221  0.219221  True\n",
       "https              0.196423  0.196423  True\n",
       "republican         0.191249  0.191249  True\n",
       "sub                0.178761  0.178761  True\n",
       "guilty             0.167608  0.167608  True\n",
       "gop                0.164102  0.164102  True\n",
       "administration     0.153353  0.153353  True\n",
       "hope               0.151132  0.151132  True\n",
       "fox                0.143517  0.143517  True\n",
       "supporters         0.135833  0.135833  True\n",
       "cohen              0.132501  0.132501  True\n",
       "white house        0.119213  0.119213  True\n",
       "draft              0.116804  0.116804  True\n",
       "office             0.114546  0.114546  True\n",
       "putin              0.114323  0.114323  True\n",
       "edit               0.111618  0.111618  True\n",
       "robert             0.109766  0.109766  True\n",
       "justice            0.108287  0.108287  True\n",
       "donnie             0.103060  0.103060  True\n",
       "american           0.103038  0.103038  True\n",
       "emails             0.102886  0.102886  True\n",
       "national           0.101725  0.101725  True\n",
       "war                0.097178  0.097178  True"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients[coefficients['sign']==True].sort_values('abs', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>abs</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!!</th>\n",
       "      <td>-0.136977</td>\n",
       "      <td>0.136977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!! love</th>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!! trump</th>\n",
       "      <td>-0.004454</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!!</th>\n",
       "      <td>-0.085022</td>\n",
       "      <td>0.085022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!!!</th>\n",
       "      <td>-0.109888</td>\n",
       "      <td>0.109888</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!!!!</th>\n",
       "      <td>-0.036153</td>\n",
       "      <td>0.036153</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!!!!!</th>\n",
       "      <td>-0.008279</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!!!!!!</th>\n",
       "      <td>-0.015263</td>\n",
       "      <td>0.015263</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!!!!!!!</th>\n",
       "      <td>-0.000702</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!!\"</th>\n",
       "      <td>-0.005621</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!\"</th>\n",
       "      <td>-0.005057</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!*</th>\n",
       "      <td>-0.007349</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!*</th>\n",
       "      <td>-0.054517</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!1</th>\n",
       "      <td>-0.005408</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!?</th>\n",
       "      <td>-0.022744</td>\n",
       "      <td>0.022744</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!]</th>\n",
       "      <td>-0.007444</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!] https</th>\n",
       "      <td>-0.003943</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, .</th>\n",
       "      <td>-0.028012</td>\n",
       "      <td>0.028012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, ...</th>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, 1</th>\n",
       "      <td>-0.008731</td>\n",
       "      <td>0.008731</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, 3</th>\n",
       "      <td>-0.005730</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, 4</th>\n",
       "      <td>-0.000323</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, 5</th>\n",
       "      <td>-0.003774</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, according</th>\n",
       "      <td>-0.005970</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, amazing</th>\n",
       "      <td>-0.001247</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coefficient       abs   sign\n",
       "!!             -0.136977  0.136977  False\n",
       "!! love        -0.000766  0.000766  False\n",
       "!! trump       -0.004454  0.004454  False\n",
       "!!!            -0.085022  0.085022  False\n",
       "!!!!           -0.109888  0.109888  False\n",
       "!!!!!          -0.036153  0.036153  False\n",
       "!!!!!!         -0.008279  0.008279  False\n",
       "!!!!!!!        -0.015263  0.015263  False\n",
       "!!!!!!!!       -0.000702  0.000702  False\n",
       "!!!\"           -0.005621  0.005621  False\n",
       "!!\"            -0.005057  0.005057  False\n",
       "!!*            -0.007349  0.007349  False\n",
       "!*             -0.054517  0.054517  False\n",
       "!1             -0.005408  0.005408  False\n",
       "!?             -0.022744  0.022744  False\n",
       "!]             -0.007444  0.007444  False\n",
       "!] https       -0.003943  0.003943  False\n",
       ", .            -0.028012  0.028012  False\n",
       ", ...          -0.007545  0.007545  False\n",
       ", 1            -0.008731  0.008731  False\n",
       ", 3            -0.005730  0.005730  False\n",
       ", 4            -0.000323  0.000323  False\n",
       ", 5            -0.003774  0.003774  False\n",
       ", according    -0.005970  0.005970  False\n",
       ", amazing      -0.001247  0.001247  False"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients[coefficients['sign']==False].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting subreddit using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "# Instantiate random forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "# Instantiate second random forest model\n",
    "rf_t = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69877049 0.6550308  0.72895277]\n",
      "0.6942513548995186\n"
     ]
    }
   ],
   "source": [
    "# find cross-val scores for rf model based on titles\n",
    "rf_score = cross_val_score(rf, X_train_cvect, y_train)\n",
    "print(rf_score)\n",
    "print(rf_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7336065573770492"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_cvect, y_train)\n",
    "rf.score(X_test_cvect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993160054719562"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train_cvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6557377  0.61601643 0.69199179]\n",
      "0.6545819728234646\n"
     ]
    }
   ],
   "source": [
    "# find cross-val scores for rf model based on titles\n",
    "rf_t_score = cross_val_score(rf, X_train_tvect, y_train)\n",
    "print(rf_t_score)\n",
    "print(rf_t_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.680327868852459"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_t.fit(X_train_tvect, y_train)\n",
    "rf_t.score(X_test_tvect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5753"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "numeric_cols = [col for col in cv.get_feature_names() if col.isnumeric()]\n",
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = list(stopwords.words('english'))\n",
    "stops.extend(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_steps = [('vect', CountVectorizer()),\n",
    "            ('rf', RandomForestClassifier())]\n",
    "\n",
    "rf_pipe = Pipeline(rf_steps)\n",
    "\n",
    "rf_params = {\n",
    "    'vect__stop_words': ('english', stops, None),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (1, 4)),\n",
    "    'vect__max_features': (1000, 2500, None),\n",
    "    'rf__n_estimators': (5, 10, 15)\n",
    "}\n",
    "\n",
    "rfgs = GridSearchCV(rf_pipe, rf_params, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['archived', 'author', 'author_flair_text', 'comments', 'domain',\n",
       "       'downs', 'gilded', 'id', 'is_reddit_media_domain', 'is_self',\n",
       "       'is_video', 'link_flair_text', 'name', 'num_comments', 'num_crossposts',\n",
       "       'post_hint', 'score', 'selftext', 'send_replies', 'subreddit', 'title',\n",
       "       'ups', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 324 out of 324 | elapsed:   54.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__stop_words': ('english', ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', '... (1, 2), (1, 3), (1, 4)), 'vect__max_features': (1000, 2500, None), 'rf__n_estimators': (5, 10, 15)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7004103967168263"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823770491803278"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_comments = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('vect', CountVectorizer()),\n",
    "         ('rf', RandomForestClassifier())]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid_params = {\n",
    "    'vect__max_features': (17500, 22500),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'rf__n_estimators': [50, 60, 70],\n",
    "    'vect__stop_words': ('english', None)\n",
    "}\n",
    "\n",
    "grid_6 = GridSearchCV(pipe, grid_params, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_features': (17500, 22500), 'vect__ngram_range': ((1, 1), (1, 2)), 'rf__n_estimators': [50, 60, 70], 'vect__stop_words': ('english', None)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.fit(X_com_train, y_com_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9110807113543091"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__n_estimators': 50,\n",
       " 'vect__max_features': 17500,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8954918032786885"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.score(X_com_test, y_com_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process using a different classifier (e.g. `MultinomialNB`, `LogisticRegression`, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_params = {\n",
    "    'n_estimators': [95, 100, 105, 110],\n",
    "    'learning_rate': [0.65, 0.7, 0.75]\n",
    "}\n",
    "ada_grid = GridSearchCV(ada, param_grid = ada_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "X7 = red_df['title'] + ' ' + red_df['selftext']\n",
    "y7 = red_df['subreddit']\n",
    "\n",
    "X7_train, X7_test, y7_train, y7_test = train_test_split(X7, y7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect7 = CountVectorizer(stop_words='english')\n",
    "X7_train_cvect = cvect7.fit_transform(X7_train)\n",
    "X7_test_cvect = cvect7.transform(X7_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [95, 100, 105, 110], 'learning_rate': [0.65, 0.7, 0.75]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid.fit(X7_train_cvect, y7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6764705882352942"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.65, 'n_estimators': 95}"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AdaBoost classifier performed poorly on the title and selftext data. It is possible that just this information alone was not robust enough to develop a strong model. Below I will try to use this same classifier with the comments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('vect', CountVectorizer()),\n",
    "         ('ada', AdaBoostClassifier())]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid_params = {\n",
    "    'vect__max_features': (17500, 22500),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'ada__learning_rate': [0.85, 0.95],\n",
    "    'ada__n_estimators': [55, 65],\n",
    "    'vect__stop_words': ('english', None)\n",
    "}\n",
    "\n",
    "grid_6 = GridSearchCV(pipe, grid_params, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...m='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_features': (17500, 22500), 'vect__ngram_range': ((1, 1), (1, 2)), 'ada__learning_rate': [0.85, 0.95], 'ada__n_estimators': [55, 65], 'vect__stop_words': ('english', None)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.fit(X_com_train, y_com_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9829001367989056"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 0.95,\n",
       " 'ada__n_estimators': 65,\n",
       " 'vect__max_features': 17500,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__stop_words': None}"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808481532147743"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 0.9,\n",
       " 'ada__n_estimators': 60,\n",
       " 'vect__max_features': 20000,\n",
       " 'vect__ngram_range': (1, 2),\n",
       " 'vect__stop_words': None,\n",
       " 'vect__tokenizer': None}"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938524590163934"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.score(X_com_test, y_com_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.DataFrame(grid_6.best_estimator_.steps[1][1].feature_importances_, columns=['importance'],\n",
    "                                index=grid_6.best_estimator_.steps[0][1].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mueller</th>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kek</th>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>republican</th>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>god</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corruption</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shills</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sister</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removed</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supporters</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geotus</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>putin</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dems</th>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            importance\n",
       "mueller       0.090909\n",
       "kek           0.036364\n",
       "trump         0.036364\n",
       "republican    0.036364\n",
       "left          0.036364\n",
       "god           0.018182\n",
       "fox           0.018182\n",
       "corruption    0.018182\n",
       "media         0.018182\n",
       "shills        0.018182\n",
       "sister        0.018182\n",
       "removed       0.018182\n",
       "opinion       0.018182\n",
       "supporters    0.018182\n",
       "years         0.018182\n",
       "geotus        0.018182\n",
       "putin         0.018182\n",
       "watch         0.018182\n",
       "don           0.018182\n",
       "dems          0.018182"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importances.sort_values('importance', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
